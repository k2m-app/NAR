import time
import json
import re
import requests
import streamlit as st
from datetime import datetime
import pytz
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

# ==================================================
# 1. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ & Secrets è¨­å®š
# ==================================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]: return True
    st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
    ADMIN_PASS = st.secrets.get("ADMIN_PASSWORD", "admin123")
    user_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if user_input == ADMIN_PASS:
            st.session_state["password_correct"] = True
            st.rerun()
        else: st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    return False

if not check_password(): st.stop()

# èªè¨¼æƒ…å ±
KEIBA_ID = st.secrets.get("KEIBA_ID", "")
KEIBA_PASS = st.secrets.get("KEIBA_PASS", "")
DIFY_API_KEY = st.secrets.get("DIFY_API_KEY", "")

# å¤‰æ›ãƒãƒƒãƒ— (ç«¶é¦¬ãƒ–ãƒƒã‚¯ID -> å—é–¢URLç”¨)
KB_TO_NANKAN_PLACE = {"10": "20", "11": "21", "12": "19", "13": "18"}
PLACE_NAMES = {"10": "å¤§äº•", "11": "å·å´", "12": "èˆ¹æ©‹", "13": "æµ¦å’Œ"}

# ==================================================
# 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚³ã‚¢ (å¯¾ç­–å¼·åŒ–ç‰ˆ)
# ==================================================

def get_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    # ãƒœãƒƒãƒˆæ¤œçŸ¥å›é¿ç”¨
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(options=options)

def get_nankan_base_id(driver, date_str, kb_place_code):
    """å—é–¢å…¬å¼ã‹ã‚‰ãƒ™ãƒ¼ã‚¹ID(14æ¡)ã‚’ç‰¹å®šã™ã‚‹"""
    nankan_place = KB_TO_NANKAN_PLACE.get(kb_place_code)
    try:
        # ã‚¯ãƒƒã‚­ãƒ¼ã‚’ç„¼ããŸã‚ã«ãƒˆãƒƒãƒ—ã¸
        driver.get("https://www.nankankeiba.com/")
        time.sleep(1)
        # ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãƒšãƒ¼ã‚¸ã¸
        url = f"https://www.nankankeiba.com/program/{date_str}{nankan_place}.do"
        driver.get(url)
        time.sleep(3)
        soup = BeautifulSoup(driver.page_source, "html.parser")

        # ãƒ—ãƒ©ãƒ³A: ãƒªãƒ³ã‚¯ã‹ã‚‰æŠ½å‡º
        links = soup.find_all("a", href=re.compile(r"race_info/\d+"))
        for l in links:
            m = re.search(r'(\d{14})', l['href'])
            if m: return m.group(1)

        # ãƒ—ãƒ©ãƒ³B: ãƒšãƒ¼ã‚¸å†…ã®ã€Œç¬¬xxå›ã€ã€Œç¬¬yyæ—¥ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”Ÿæˆ
        txt = soup.get_text()
        k_match = re.search(r'ç¬¬\s*(\d+)\s*å›', txt)
        n_match = re.search(r'ç¬¬\s*(\d+)\s*æ—¥', txt)
        if k_match and n_match:
            k = k_match.group(1).zfill(2)
            n = n_match.group(1).zfill(2)
            return f"{date_str}{nankan_place}{k}{n}"
    except: pass
    return None

def fetch_book_race_ids(driver, date_str, kb_place_code):
    """ç«¶é¦¬ãƒ–ãƒƒã‚¯ã‹ã‚‰å¯¾è±¡å ´æ‰€ã®å…¨ãƒ¬ãƒ¼ã‚¹ID(16æ¡)ã‚’å–å¾—"""
    url = f"https://s.keibabook.co.jp/chihou/nittei/{date_str}10"
    driver.get(url)
    time.sleep(2)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    ids = []
    for a in soup.find_all("a", href=re.compile(r'/chihou/syutuba/\d{16}')):
        rid = re.search(r'(\d{16})', a['href']).group(1)
        if rid[6:8] == kb_place_code and rid not in ids:
            ids.append(rid)
    return sorted(ids)

def fetch_nankan_compatibility(driver, base_id, r_num, h_num):
    """å—é–¢ã®ç›¸æ€§è¡¨ã‹ã‚‰ã€å©èˆæ‰€å±é¦¬ã€æˆç¸¾ã‚’ãƒ”ãƒ³ãƒã‚¤ãƒ³ãƒˆæŠ½å‡º"""
    url = f"https://www.nankankeiba.com/aisyou_cho/{base_id}{str(r_num).zfill(2)}01{str(h_num).zfill(2)}.do"
    try:
        driver.get(url)
        time.sleep(0.5)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        # nk23æ–°ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ»æ—§ãƒ‡ã‚¶ã‚¤ãƒ³ä¸¡å¯¾å¿œ
        table = soup.find("table", class_=re.compile(r"nk23_c-table01|maintable"))
        rows = table.find_all("tr") if table else soup.find_all("tr")
        for row in rows:
            if "å©èˆæ‰€å±é¦¬" in row.get_text():
                tds = row.find_all("td")
                return f"å‹ç‡{tds[4].text.strip()} / é€£å¯¾ç‡{tds[5].text.strip()}"
    except: pass
    return "ãƒ‡ãƒ¼ã‚¿ãªã—"

def get_race_details(driver, rid):
    """ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®å‡ºé¦¬è¡¨ãƒ»è«‡è©±ãƒ»èª¿æ•™ã‚’çµ±åˆå–å¾—"""
    data = {"jockeys": {}, "danwas": {}, "trainings": {}}
    # 1. å‡ºé¦¬è¡¨ (é¨æ‰‹ãƒ»ä¹—ã‚Šæ›¿ã‚ã‚Š)
    driver.get(f"https://s.keibabook.co.jp/chihou/syutuba/{rid}")
    soup = BeautifulSoup(driver.page_source, "html.parser")
    tbl = soup.find("table", class_="syutuba_sp")
    if tbl:
        for r in tbl.find_all("tr"):
            tds = r.find_all("td")
            if tds and tds[0].text.strip().isdigit():
                u = tds[0].text.strip()
                kp = r.find("p", class_="kisyu")
                if kp and kp.find("a"):
                    a = kp.find("a")
                    data["jockeys"][u] = {"name": a.text.strip(), "change": bool(a.find("strong"))}
    # 2. è«‡è©±
    driver.get(f"https://s.keibabook.co.jp/chihou/danwa/1/{rid}")
    soup = BeautifulSoup(driver.page_source, "html.parser")
    tbl = soup.find("table", class_="danwa")
    if tbl:
        cur = None
        for r in tbl.find_all("tr"):
            u_td = r.find("td", class_="umaban")
            if u_td: cur = u_td.text.strip()
            txt = r.find("td", class_="danwa")
            if txt and cur: data["danwas"][cur] = txt.text.strip()
    # 3. èª¿æ•™
    driver.get(f"https://s.keibabook.co.jp/chihou/cyokyo/1/{rid}")
    soup = BeautifulSoup(driver.page_source, "html.parser")
    for t in soup.find_all("table", class_="cyokyo"):
        u = t.find("td", class_="umaban")
        tp = t.find("td", class_="tanpyo")
        if u and tp: data["trainings"][u.text.strip()] = tp.text.strip()
    return data

def call_dify(text):
    if not DIFY_API_KEY: return "AIåˆ†æã‚­ãƒ¼æœªè¨­å®š"
    payload = {"inputs": {"text": text}, "response_mode": "blocking", "user": "keiba-user"}
    headers = {"Authorization": f"Bearer {DIFY_API_KEY}", "Content-Type": "application/json"}
    try:
        res = requests.post("https://api.dify.ai/v1/workflows/run", headers=headers, json=payload, timeout=120)
        return res.json().get("data", {}).get("outputs", {}).get("text", "åˆ†æå®Œäº†")
    except: return "AIé€šä¿¡ã‚¨ãƒ©ãƒ¼"

# ==================================================
# 3. ãƒ¡ã‚¤ãƒ³UI
# ==================================================
st.title("ğŸ‡ å—é–¢Ã—ãƒ–ãƒƒã‚¯ çµ±åˆåˆ†æBot")

jst = pytz.timezone('Asia/Tokyo')
now = datetime.now(jst)

# è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
with st.container():
    c1, c2 = st.columns(2)
    with c1: target_date = st.date_input("åˆ†ææ—¥", now)
    with c2: place_code = st.selectbox("ç«¶é¦¬å ´", options=list(PLACE_NAMES.keys()), format_func=lambda x: f"{x}:{PLACE_NAMES[x]}", index=1)

    st.write("### ğŸ ãƒ¬ãƒ¼ã‚¹é¸æŠ")
    all_races = st.checkbox("å…¨ãƒ¬ãƒ¼ã‚¹ã‚’ä¸€æ‹¬åˆ†æã™ã‚‹", value=True)
    selected_races = []
    if not all_races:
        cols = st.columns(6)
        for i in range(1, 13):
            with cols[(i-1)//2]:
                if st.checkbox(f"{i}R", key=f"r{i}"): selected_races.append(i)
    else: selected_races = list(range(1, 13))

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸš€ åˆ†æã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    date_str = target_date.strftime("%Y%m%d")
    driver = get_driver()
    
    try:
        st.write("ğŸ”‘ ç«¶é¦¬ãƒ–ãƒƒã‚¯ã¸ãƒ­ã‚°ã‚¤ãƒ³...")
        driver.get("https://s.keibabook.co.jp/login/login")
        driver.find_element(By.NAME, "login_id").send_keys(KEIBA_ID)
        driver.find_element(By.CSS_SELECTOR, "input[type='password']").send_keys(KEIBA_PASS)
        driver.find_element(By.CSS_SELECTOR, "input[type='submit']").click()
        
        st.write("ğŸ“¡ å…±é€šIDã‚’ç”Ÿæˆä¸­...")
        nankan_base_id = get_nankan_base_id(driver, date_str, place_code)
        book_ids = fetch_book_race_ids(driver, date_str, place_code)
        
        if not nankan_base_id or not book_ids:
            st.error("é–‹å‚¬æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚æ—¥ä»˜ã‚„å ´æ‰€ã€ä¼‘å‚¬æ—¥ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            st.success(f"IDç´ä»˜ã‘æˆåŠŸ: å—é–¢BaseID[{nankan_base_id}]")
            
            for rid in book_ids:
                r_num = int(rid[10:12]) # ç«¶é¦¬ãƒ–ãƒƒã‚¯IDã®11-12æ¡ç›®
                if r_num not in selected_races: continue
                
                with st.expander(f"ğŸ“Š {PLACE_NAMES[place_code]} {r_num}R åˆ†æ", expanded=True):
                    status = st.empty()
                    status.info(f"{r_num}R ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...")
                    
                    # ç«¶é¦¬ãƒ–ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿å–å¾—
                    details = get_race_details(driver, rid)
                    
                    # å—é–¢ç›¸æ€§ã¨çµåˆ
                    merged = []
                    for uma in sorted(details["jockeys"].keys(), key=int):
                        j = details["jockeys"][uma]
                        compat = fetch_nankan_compatibility(driver, nankan_base_id, r_num, uma)
                        merged.append(
                            f"â–¼[é¦¬ç•ª{uma}] {j['name']} {'ã€âš ï¸ä¹—ã‚Šæ›¿ã‚ã‚Šã€‘' if j['change'] else ''}\n"
                            f" ç›¸æ€§: {compat}\n"
                            f" è«‡è©±: {details['danwas'].get(uma, 'ãªã—')}\n"
                            f" èª¿æ•™: {details['trainings'].get(uma, 'ãªã—')}"
                        )
                    
                    full_prompt = f"{PLACE_NAMES[place_code]} {r_num}R\n" + "\n".join(merged)
                    
                    status.info("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œä¸­...")
                    ans = call_dify(full_prompt)
                    st.markdown(ans)
                    status.success("åˆ†æå®Œäº†")
                    
    finally:
        driver.quit()
