import time
import json
import re
import requests
import streamlit as st
from datetime import datetime
import pytz
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from supabase import create_client, Client

# ==================================================
# 1. è¨­å®šãƒ»å®šæ•°ãƒ»Secretsèª­ã¿è¾¼ã¿
# ==================================================

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼ˆç°¡æ˜“ï¼‰
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]: return True
    
    st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
    ADMIN_PASS = st.secrets.get("ADMIN_PASSWORD", "admin123")
    user_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if user_input == ADMIN_PASS:
            st.session_state["password_correct"] = True
            st.rerun()
        else: st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    return False

if not check_password(): st.stop()

# èªè¨¼æƒ…å ±ã®èª­ã¿è¾¼ã¿
KEIBA_ID = st.secrets.get("KEIBA_ID", "")
KEIBA_PASS = st.secrets.get("KEIBA_PASS", "")
NETKEIBA_EMAIL = st.secrets.get("NETKEIBA_EMAIL", "")
NETKEIBA_PASS = st.secrets.get("NETKEIBA_PASS", "")
DIFY_API_KEY = st.secrets.get("DIFY_API_KEY", "")
SUPABASE_URL = st.secrets.get("SUPABASE_URL", "")
SUPABASE_ANON_KEY = st.secrets.get("SUPABASE_ANON_KEY", "")

# å ´æ‰€ã‚³ãƒ¼ãƒ‰å¤‰æ›ãƒãƒƒãƒ— (ç«¶é¦¬ãƒ–ãƒƒã‚¯ -> Netkeiba)
KB_TO_NK_CODE = {
    "10": "44", # å¤§äº•
    "11": "45", # å·å´
    "12": "43", # èˆ¹æ©‹
    "13": "42"  # æµ¦å’Œ
}
PLACE_NAMES = {"10": "å¤§äº•", "11": "å·å´", "12": "èˆ¹æ©‹", "13": "æµ¦å’Œ"}

# ==================================================
# 2. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (Supabase, Driver)
# ==================================================

@st.cache_resource
def get_supabase_client() -> Client | None:
    if not SUPABASE_URL or not SUPABASE_ANON_KEY: return None
    return create_client(SUPABASE_URL, SUPABASE_ANON_KEY)

def save_history(year, place_code, place_name, month, day, race_num_str, race_id, ai_answer):
    """Supabaseã«å±¥æ­´ã‚’ä¿å­˜"""
    supabase = get_supabase_client()
    if not supabase: return
    data = {
        "year": str(year),
        "place_code": str(place_code),
        "place_name": place_name,
        "day": str(day),
        "month": str(month),
        "race_num": race_num_str,
        "race_id": race_id,
        "output_text": ai_answer,
    }
    try:
        supabase.table("history").insert(data).execute()
    except Exception as e:
        st.error(f"Supabase save error: {e}")

def get_driver():
    """Seleniumãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã®èµ·å‹•è¨­å®š"""
    options = Options()
    options.add_argument("--headless") # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1280,1080")
    # Botæ¤œçŸ¥å›é¿ã®ãŸã‚ã®User-Agent
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(options=options)

# ==================================================
# 3. ç«¶é¦¬ãƒ–ãƒƒã‚¯ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•°
# ==================================================

def login_keibabook(driver):
    if not KEIBA_ID or not KEIBA_PASS:
        st.warning("âš ï¸ ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®ID/PASSãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return False
    try:
        driver.get("https://s.keibabook.co.jp/login/login")
        # è¦ç´ ãŒè¦‹ã¤ã‹ã‚‹ã¾ã§å¾…æ©Ÿ
        WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.NAME, "login_id"))).send_keys(KEIBA_ID)
        driver.find_element(By.CSS_SELECTOR, "input[type='password']").send_keys(KEIBA_PASS)
        driver.find_element(By.CSS_SELECTOR, "input[type='submit']").click()
        time.sleep(1)
        return True
    except Exception as e:
        st.error(f"ç«¶é¦¬ãƒ–ãƒƒã‚¯ ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def fetch_race_ids_from_schedule(driver, year, month, day, target_place_code):
    """æ—¥ç¨‹ãƒšãƒ¼ã‚¸ã‹ã‚‰å¯¾è±¡ç«¶é¦¬å ´ã®å…¨ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—"""
    date_str = f"{year}{month}{day}"
    url = f"https://s.keibabook.co.jp/chihou/nittei/{date_str}10" # æœ«å°¾10ã¯åœ°æ–¹ãƒˆãƒƒãƒ—å›ºå®š
    
    st.info(f"ğŸ“… æ—¥ç¨‹å–å¾—ä¸­: {url}")
    driver.get(url)
    time.sleep(1)
    
    soup = BeautifulSoup(driver.page_source, "html.parser")
    race_ids = []
    seen = set()
    
    # ãƒªãƒ³ã‚¯ã‹ã‚‰IDæŠ½å‡º
    for a in soup.find_all("a", href=True):
        href = a['href']
        match = re.search(r'(\d{16})', href)
        if match:
            rid = match.group(1)
            # IDã®6-7æ–‡å­—ç›®(å ´æ‰€ã‚³ãƒ¼ãƒ‰)ãŒä¸€è‡´ã™ã‚‹ã‹
            if rid[6:8] == target_place_code:
                if rid not in seen:
                    race_ids.append(rid)
                    seen.add(rid)
    race_ids.sort()
    return race_ids

def parse_race_info(html: str):
    """ãƒ¬ãƒ¼ã‚¹åãƒ»æ¡ä»¶ãªã©ã‚’å–å¾—"""
    soup = BeautifulSoup(html, "html.parser")
    racetitle = soup.find("div", class_="racetitle")
    if not racetitle: return {}
    
    racemei = racetitle.find("div", class_="racemei")
    race_name = racemei.find_all("p")[1].get_text(strip=True) if racemei and len(racemei.find_all("p")) >= 2 else ""
    
    sub = racetitle.find("div", class_="racetitle_sub")
    cond = sub.find_all("p")[1].get_text(" ", strip=True) if sub and len(sub.find_all("p")) >= 2 else ""
    return {"race_name": race_name, "cond": cond}

def parse_danwa_comments(html: str):
    """è«‡è©±ã‚’å–å¾—"""
    soup = BeautifulSoup(html, "html.parser")
    danwa_dict = {}
    table = soup.find("table", class_="danwa")
    if table and table.tbody:
        current_uma = None
        for row in table.tbody.find_all("tr"):
            uma_td = row.find("td", class_="umaban")
            if uma_td:
                current_uma = uma_td.get_text(strip=True)
                continue
            txt_td = row.find("td", class_="danwa")
            if txt_td and current_uma:
                danwa_dict[current_uma] = txt_td.get_text(strip=True)
                current_uma = None
    return danwa_dict

def parse_syutuba_jockey(html: str):
    """å‡ºé¦¬è¡¨ã‹ã‚‰é¨æ‰‹ãƒ»ä¹—ã‚Šæ›¿ã‚ã‚Šæƒ…å ±ã‚’å–å¾—"""
    soup = BeautifulSoup(html, "html.parser")
    jockey_info = {}
    table = soup.find("table", class_="syutuba_sp")
    if not table or not table.find("tbody"): return {}

    for row in table.find("tbody").find_all("tr"):
        tds = row.find_all("td")
        if not tds: continue
        
        # 1åˆ—ç›®ãŒé¦¬ç•ª
        umaban_text = tds[0].get_text(strip=True)
        if not umaban_text.isdigit(): continue
        umaban = umaban_text
        
        # é¨æ‰‹æƒ…å ±
        kisyu_p = row.find("p", class_="kisyu")
        if kisyu_p and kisyu_p.find("a"):
            anchor = kisyu_p.find("a")
            name = anchor.get_text(strip=True)
            is_change = bool(anchor.find("strong"))
            jockey_info[umaban] = {"name": name, "is_change": is_change}
            
    return jockey_info

def parse_cyokyo(html: str):
    """èª¿æ•™ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    soup = BeautifulSoup(html, "html.parser")
    cyokyo_dict = {}
    tables = soup.find_all("table", class_="cyokyo")
    for tbl in tables:
        tbody = tbl.find("tbody")
        if not tbody: continue
        rows = tbody.find_all("tr", recursive=False)
        if not rows: continue
        
        h_row = rows[0]
        uma_td = h_row.find("td", class_="umaban")
        name_td = h_row.find("td", class_="kbamei")
        if not uma_td or not name_td: continue
        
        umaban = uma_td.get_text(strip=True)
        bamei = name_td.get_text(" ", strip=True)
        tanpyo = h_row.find("td", class_="tanpyo").get_text(strip=True) if h_row.find("td", class_="tanpyo") else ""
        detail = rows[1].get_text(" ", strip=True) if len(rows) > 1 else ""
        
        cyokyo_dict[umaban] = f"ã€é¦¬åã€‘{bamei} ã€çŸ­è©•ã€‘{tanpyo} ã€è©³ç´°ã€‘{detail}"
    return cyokyo_dict

# ==================================================
# 4. Netkeiba ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° (ä¿®æ­£ç‰ˆ)
# ==================================================

def login_netkeiba(driver):
    """Netkeibaã«ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    if not NETKEIBA_EMAIL or not NETKEIBA_PASS:
        st.warning("âš ï¸ Netkeibaã®ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return False
    try:
        login_url = "https://regist.netkeiba.com/account/?pid=login"
        driver.get(login_url)
        
        # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾…æ©Ÿ (æœ€å¤§10ç§’)
        wait = WebDriverWait(driver, 10)
        
        # ãƒ­ã‚°ã‚¤ãƒ³ãƒ•ã‚©ãƒ¼ãƒ ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‹ç¢ºèª
        if "logout" in driver.page_source:
            st.info("âœ… Netkeiba: æ—¢ã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿")
            return True
            
        # IDå…¥åŠ›å¾…æ©Ÿ
        login_id_input = wait.until(EC.visibility_of_element_located((By.NAME, "login_id")))
        login_id_input.clear()
        login_id_input.send_keys(NETKEIBA_EMAIL)
        
        # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›
        password_input = driver.find_element(By.NAME, "pswd")
        password_input.clear()
        password_input.send_keys(NETKEIBA_PASS)
        
        # â˜…ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: ãƒœã‚¿ãƒ³ã‚’æ¢ã•ãšã€ãƒ•ã‚©ãƒ¼ãƒ ã‚’submitã™ã‚‹
        password_input.submit()
        
        time.sleep(2) # é·ç§»å¾…ã¡
        return True
        
    except Exception as e:
        st.error(f"Netkeiba ãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def get_netkeiba_speed_url(year, month, day, kb_place_code, race_num):
    """Netkeibaã®ã‚¿ã‚¤ãƒ æŒ‡æ•°URLç”Ÿæˆ"""
    nk_place = KB_TO_NK_CODE.get(kb_place_code)
    if not nk_place: return None
    date_str = f"{month.zfill(2)}{day.zfill(2)}"
    race_str = str(race_num).zfill(2)
    # IDæ§‹æˆ: YYYY + NKå ´æ‰€ã‚³ãƒ¼ãƒ‰ + MMDD + RR
    race_id = f"{year}{nk_place}{date_str}{race_str}"
    return f"https://nar.netkeiba.com/race/speed.html?race_id={race_id}&type=shutuba&mode=past"

def scrape_netkeiba_speed_index(driver, url, current_place_name):
    """ã‚¿ã‚¤ãƒ æŒ‡æ•°ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    data = {}
    try:
        driver.get(url)
        time.sleep(1)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        
        # ç¾åœ¨ã®ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ (ä¾‹: "å¤§äº•ãƒ€1400")
        current_condition = ""
        race_data_div = soup.find("div", class_="RaceData01")
        if race_data_div:
            text = race_data_div.get_text()
            dist_match = re.search(r'(\d{3,4})m', text)
            if dist_match:
                track_type = "èŠ" if "èŠ" in text else "ãƒ€"
                current_condition = f"{current_place_name}{track_type}{dist_match.group(1)}"
        
        table = soup.find("table", class_="SpeedIndex_Table")
        if not table: return {}
        
        rows = table.find_all("tr", class_="HorseList")
        for row in rows:
            try:
                # é¦¬ç•ª
                umaban_td = row.find("td", class_=re.compile("umaban", re.I))
                if not umaban_td: continue
                umaban = umaban_td.get_text(strip=True)
                
                # æŒ‡æ•°ãƒ‡ãƒ¼ã‚¿ã®é–‹å§‹åˆ—ç‰¹å®š
                cols = row.find_all("td")
                start_idx = -1
                for i, col in enumerate(cols):
                    if "Horse_Name" in " ".join(col.get("class", [])):
                        start_idx = i + 1
                        break
                if start_idx == -1: continue
                
                # è¿‘5èµ°ãƒ‡ãƒ¼ã‚¿å–å¾— (start_idx+1 ã‹ã‚‰ 5ã¤åˆ†)
                target_cols = cols[start_idx+1 : start_idx+6]
                past_list = []
                speed_match_list = []
                
                for td in target_cols:
                    course_span = td.find("span")
                    if not course_span: continue
                    course_str = course_span.get_text(strip=True)
                    
                    idx_a = td.find("a")
                    idx_val = idx_a.get_text(strip=True) if idx_a else "-"
                    
                    if idx_val.isdigit():
                        past_list.append(f"{course_str}({idx_val})")
                        # åŒæ¡ä»¶åˆ¤å®š (éƒ¨åˆ†ä¸€è‡´)
                        if current_condition and current_condition in course_str:
                            speed_match_list.append(idx_val)
                            
                data[umaban] = {
                    "past": " / ".join(past_list) if past_list else "ãªã—",
                    "speed_index": ", ".join(speed_match_list) if speed_match_list else "è©²å½“ãªã—",
                    "condition": current_condition
                }
            except: continue
            
        return data
    except Exception as e:
        return {} # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™

# ==================================================
# 5. Dify APIé€£æº (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°)
# ==================================================

def stream_dify_workflow(full_text: str):
    if not DIFY_API_KEY:
        yield "âš ï¸ DIFY_API_KEYæœªè¨­å®š"
        return
    
    payload = {"inputs": {"text": full_text}, "response_mode": "streaming", "user": "keiba-bot"}
    headers = {"Authorization": f"Bearer {DIFY_API_KEY}", "Content-Type": "application/json"}
    
    try:
        res = requests.post("https://api.dify.ai/v1/workflows/run", headers=headers, json=payload, stream=True, timeout=300)
        for line in res.iter_lines():
            if line:
                decoded = line.decode('utf-8')
                if decoded.startswith("data:"):
                    try:
                        data = json.loads(decoded.replace("data: ", ""))
                        if "answer" in data:
                            yield data.get("answer", "")
                    except: pass
    except Exception as e:
        yield f"âš ï¸ API Error: {str(e)}"

# ==================================================
# 6. ãƒ¡ã‚¤ãƒ³ç”»é¢ãƒ»å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯
# ==================================================

st.title("ğŸ‡ å—é–¢Ã—ãƒ–ãƒƒã‚¯Ã—NK çµ±åˆåˆ†æBot")
jst = pytz.timezone('Asia/Tokyo')
now = datetime.now(jst)

# è¨­å®šUI
with st.container():
    c1, c2 = st.columns(2)
    with c1: target_date = st.date_input("åˆ†ææ—¥", now)
    with c2: 
        # å ´æ‰€ã‚³ãƒ¼ãƒ‰ã®é¸æŠè‚¢
        PLACE_CODE = st.selectbox("é–‹å‚¬å ´æ‰€", ["10", "11", "12", "13"], 
                                  format_func=lambda x: f"{x}: {PLACE_NAMES.get(x)}")
    
    st.write("### ğŸ ãƒ¬ãƒ¼ã‚¹é¸æŠ")
    all_races = st.checkbox("å…¨ãƒ¬ãƒ¼ã‚¹ã‚’ä¸€æ‹¬åˆ†æã™ã‚‹", value=True)
    target_races = []
    if not all_races:
        cols = st.columns(6)
        for i in range(1, 13):
            with cols[(i-1)//2]:
                if st.checkbox(f"{i}R", key=f"r{i}"): target_races.append(i)
    else:
        target_races = list(range(1, 13))

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸš€ åˆ†æé–‹å§‹", type="primary"):
    # æ—¥ä»˜æ–‡å­—åˆ—ã®æº–å‚™
    date_str = target_date.strftime("%Y%m%d")
    year_str = target_date.strftime("%Y")
    month_str = target_date.strftime("%m")
    day_str = target_date.strftime("%d")
    place_name = PLACE_NAMES.get(PLACE_CODE, "ä¸æ˜")

    driver = get_driver()
    
    try:
        st.info("ğŸ”‘ å„ã‚µã‚¤ãƒˆã¸ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")
        login_keibabook(driver)
        
        # Netkeibaãƒ­ã‚°ã‚¤ãƒ³ (ã‚¿ã‚¤ãƒ æŒ‡æ•°ç”¨)
        if login_netkeiba(driver):
            st.success("âœ… Netkeibaãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸ")
        else:
            st.warning("âš ï¸ Netkeibaãƒ­ã‚°ã‚¤ãƒ³å¤±æ•— (ã‚¿ã‚¤ãƒ æŒ‡æ•°ã¯å–å¾—ã§ããªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™)")

        st.info("ğŸ“¡ ãƒ¬ãƒ¼ã‚¹IDã‚’å–å¾—ä¸­...")
        race_ids = fetch_race_ids_from_schedule(driver, year_str, month_str, day_str, PLACE_CODE)
        
        if not race_ids:
            st.error("ãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # å–å¾—ã—ãŸIDã”ã¨ã«ãƒ«ãƒ¼ãƒ—
            for race_id in race_ids:
                race_num = int(race_id[10:12]) # IDã®11,12æ¡ç›®ãŒãƒ¬ãƒ¼ã‚¹ç•ªå·
                if target_races and race_num not in target_races:
                    continue
                
                st.markdown(f"### {place_name} {race_num}R")
                status_area = st.empty()
                result_area = st.empty()
                
                try:
                    status_area.info("ğŸ“š ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
                    
                    # A. ç«¶é¦¬ãƒ–ãƒƒã‚¯æƒ…å ± (è«‡è©±ãƒ»é¨æ‰‹ãƒ»èª¿æ•™)
                    driver.get(f"https://s.keibabook.co.jp/chihou/danwa/1/{race_id}")
                    html_danwa = driver.page_source
                    race_meta = parse_race_info(html_danwa)
                    danwa_dict = parse_danwa_comments(html_danwa)
                    
                    driver.get(f"https://s.keibabook.co.jp/chihou/syutuba/{race_id}")
                    jockey_dict = parse_syutuba_jockey(driver.page_source)
                    
                    driver.get(f"https://s.keibabook.co.jp/chihou/cyokyo/1/{race_id}")
                    cyokyo_dict = parse_cyokyo(driver.page_source)
                    
                    # B. Netkeibaæƒ…å ± (ã‚¿ã‚¤ãƒ æŒ‡æ•°)
                    nk_url = get_netkeiba_speed_url(year_str, month_str, day_str, PLACE_CODE, race_num)
                    nk_data = {}
                    if nk_url:
                        nk_data = scrape_netkeiba_speed_index(driver, nk_url, place_name)
                    
                    # C. ãƒ‡ãƒ¼ã‚¿çµåˆ
                    merged_text = []
                    # å…¨é¦¬ç•ªã®ãƒªã‚¹ãƒˆä½œæˆ
                    all_uma = sorted(list(set(list(jockey_dict.keys()) + list(nk_data.keys()))), 
                                     key=lambda x: int(x) if x.isdigit() else 999)
                    
                    for uma in all_uma:
                        j = jockey_dict.get(uma, {"name": "ä¸æ˜", "is_change": False})
                        d = danwa_dict.get(uma, "ï¼ˆãªã—ï¼‰")
                        c = cyokyo_dict.get(uma, "ï¼ˆãªã—ï¼‰")
                        nk = nk_data.get(uma, {})
                        
                        speed_idx = nk.get("speed_index", "ãªã—")
                        condition = nk.get("condition", "ä¸æ˜")
                        
                        # ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ã®å¼·èª¿è¡¨ç¤º
                        speed_txt = ""
                        if speed_idx != "ãªã—" and speed_idx != "è©²å½“ãªã—":
                            speed_txt = f"â˜…ã€çµ¶å¯¾ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°(åŒæ¡ä»¶:{condition})ã€‘: {speed_idx}"
                        
                        alert = "ã€âš ï¸ä¹—ã‚Šæ›¿ã‚ã‚Šã€‘" if j["is_change"] else ""
                        
                        line = (
                            f"â–¼[é¦¬ç•ª{uma}] {j['name']} {alert}\n"
                            f" {speed_txt}\n"
                            f" è¿‘5èµ°æŒ‡æ•°: {nk.get('past', '-')}\n"
                            f" è«‡è©±: {d}\n"
                            f" èª¿æ•™: {c}"
                        )
                        merged_text.append(line)

                    if not merged_text:
                        status_area.warning("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue

                    # D. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
                    prompt = (
                        f"ãƒ¬ãƒ¼ã‚¹å: {race_meta.get('race_name','')}\n"
                        f"æ¡ä»¶: {race_meta.get('cond','')}\n\n"
                        "ä»¥ä¸‹ã®å„é¦¬ã®ãƒ‡ãƒ¼ã‚¿ï¼ˆé¨æ‰‹ã€ã‚¿ã‚¤ãƒ æŒ‡æ•°ã€è«‡è©±ã€èª¿æ•™ï¼‰ã‹ã‚‰ã€æ¨å¥¨é¦¬ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚\n"
                        "ç‰¹ã«ã€Œçµ¶å¯¾ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ã€ãŒé«˜ã„é¦¬ã€ãŠã‚ˆã³ã€Œä¹—ã‚Šæ›¿ã‚ã‚Šã€ã®æœ‰ç„¡ã‚’é‡è¦–ã™ã‚‹ã“ã¨ã€‚\n\n"
                        + "\n".join(merged_text)
                    )
                    
                    # E. AIåˆ†æ (ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º)
                    status_area.info("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œä¸­...")
                    full_ans = ""
                    for chunk in stream_dify_workflow(prompt):
                        full_ans += chunk
                        result_area.markdown(full_ans + "â–Œ")
                    
                    result_area.markdown(full_ans)
                    status_area.success("åˆ†æå®Œäº†")
                    
                    # F. ä¿å­˜
                    save_history(year_str, PLACE_CODE, place_name, month_str, day_str, f"{race_num:02}", race_id, full_ans)
                    
                except Exception as e:
                    status_area.error(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
                
                st.divider()

    finally:
        driver.quit()
