import time
import json
import re
import requests
import streamlit as st
from datetime import datetime
import pytz
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

# ==================================================
# 1. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ & è¨­å®š
# ==================================================
def check_password():
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False
    if st.session_state["password_correct"]: return True
    st.title("ğŸ”’ ãƒ­ã‚°ã‚¤ãƒ³")
    ADMIN_PASS = st.secrets.get("ADMIN_PASSWORD", "admin123")
    user_input = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if user_input == ADMIN_PASS:
            st.session_state["password_correct"] = True
            st.rerun()
        else: st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™")
    return False

if not check_password(): st.stop()

# Secrets
KEIBA_ID = st.secrets.get("KEIBA_ID", "")
KEIBA_PASS = st.secrets.get("KEIBA_PASS", "")
DIFY_API_KEY = st.secrets.get("DIFY_API_KEY", "")

# å¤‰æ›ãƒãƒƒãƒ—
KB_TO_NANKAN_PLACE = {"10": "20", "11": "21", "12": "19", "13": "18"}
PLACE_NAMES = {"10": "å¤§äº•", "11": "å·å´", "12": "èˆ¹æ©‹", "13": "æµ¦å’Œ"}

# ==================================================
# 2. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–¢æ•° (å¼·åŒ–ç‰ˆ)
# ==================================================

def get_driver():
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    # ãƒœãƒƒãƒˆæ¤œçŸ¥å›é¿ç”¨ã®User-Agent
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(options=options)

def get_nankan_base_id(driver, date_str, kb_place_code):
    """å—é–¢å…¬å¼ã‹ã‚‰ãƒ™ãƒ¼ã‚¹IDã‚’å–å¾—ï¼ˆã‚ˆã‚ŠæŸ”è»Ÿãªæ¤œç´¢ã«å¤‰æ›´ï¼‰"""
    nankan_place = KB_TO_NANKAN_PLACE.get(kb_place_code)
    url = f"https://www.nankankeiba.com/program/{date_str}{nankan_place}.do"
    try:
        driver.get(url)
        time.sleep(3) # èª­ã¿è¾¼ã¿å¾…ã¡ã‚’é•·ã‚ã«
        soup = BeautifulSoup(driver.page_source, "html.parser")
        
        # race_infoã‚’å«ã‚€å…¨ã¦ã®ãƒªãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        all_links = soup.find_all("a", href=True)
        for link in all_links:
            href = link['href']
            # YYYYMMDD + PlaceCode ã‚’å«ã‚€14ã€œ16æ¡ã®æ•°å­—ã‚’æ¢ã™
            match = re.search(rf'({date_str}{nankan_place}\d{{4}})', href)
            if match:
                base_id = match.group(1)
                return base_id
        
        # äºˆå‚™ï¼šãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰é–‹å‚¬å›ã‚’å–å¾—ï¼ˆä¾‹ï¼šç¬¬14å›ï¼‰
        page_text = soup.get_text()
        kaisuu_match = re.search(r'ç¬¬(\d+)å›', page_text)
        nichiji_match = re.search(r'ç¬¬(\d+)æ—¥', page_text)
        if kaisuu_match and nichiji_match:
            k = kaisuu_match.group(1).zfill(2)
            n = nichiji_match.group(1).zfill(2)
            return f"{date_str}{nankan_place}{k}{n}"
            
    except Exception as e:
        st.error(f"å—é–¢ãƒ™ãƒ¼ã‚¹IDå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
    return None

def fetch_book_race_ids(driver, date_str, kb_place_code):
    """ç«¶é¦¬ãƒ–ãƒƒã‚¯ã‹ã‚‰å…¨ãƒ¬ãƒ¼ã‚¹IDå–å¾—"""
    url = f"https://s.keibabook.co.jp/chihou/nittei/{date_str}10"
    try:
        driver.get(url)
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        ids = []
        for a in soup.find_all("a", href=True):
            match = re.search(r'(\d{16})', a['href'])
            if match:
                rid = match.group(1)
                if rid[6:8] == kb_place_code and rid not in ids:
                    ids.append(rid)
        return sorted(ids)
    except: return []

def fetch_jockey_trainer_stats(driver, base_id, r_num, h_num):
    """å—é–¢å…¬å¼ã‹ã‚‰ç›¸æ€§ãƒ‡ãƒ¼ã‚¿(nk23å¯¾å¿œ)ã‚’å–å¾—"""
    # base_id(14æ¡) + ãƒ¬ãƒ¼ã‚¹(2æ¡) + å›ºå®š(01) + é¦¬ç•ª(2æ¡)
    url = f"https://www.nankankeiba.com/aisyou_cho/{base_id}{str(r_num).zfill(2)}01{str(h_num).zfill(2)}.do"
    try:
        driver.get(url)
        time.sleep(0.5)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        # æ–°ã‚µã‚¤ãƒˆæ§‹é€ (nk23)ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        table = soup.find("table", class_=re.compile("nk23_c-table01"))
        if not table:
            # æ—§ã‚µã‚¤ãƒˆæ§‹é€ ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            rows = soup.find_all("tr")
        else:
            rows = table.find_all("tr")
            
        for row in rows:
            if "å©èˆæ‰€å±é¦¬" in row.get_text():
                tds = row.find_all("td")
                if len(tds) >= 6:
                    return f"å‹ç‡{tds[4].text.strip()} é€£å¯¾ç‡{tds[5].text.strip()}"
    except: pass
    return "ãƒ‡ãƒ¼ã‚¿ãªã—"

def parse_book_data(driver, race_id):
    """ç«¶é¦¬ãƒ–ãƒƒã‚¯ã®å‡ºé¦¬è¡¨ãƒ»è«‡è©±ãƒ»èª¿æ•™ã‚’å–å¾—"""
    # å‡ºé¦¬è¡¨
    driver.get(f"https://s.keibabook.co.jp/chihou/syutuba/{race_id}")
    time.sleep(1)
    soup = BeautifulSoup(driver.page_source, "html.parser")
    jockeys = {}
    table = soup.find("table", class_="syutuba_sp")
    if table:
        for row in table.find_all("tr"):
            tds = row.find_all("td")
            if tds and tds[0].text.strip().isdigit():
                u = tds[0].text.strip()
                kp = row.find("p", class_="kisyu")
                if kp and kp.find("a"):
                    a = kp.find("a")
                    jockeys[u] = {"name": a.text.strip(), "is_change": bool(a.find("strong"))}
    
    # è«‡è©±
    driver.get(f"https://s.keibabook.co.jp/chihou/danwa/1/{race_id}")
    time.sleep(1)
    soup_d = BeautifulSoup(driver.page_source, "html.parser")
    danwas = {}
    tbl_d = soup_d.find("table", class_="danwa")
    if tbl_d:
        cur = None
        for r in tbl_d.find_all("tr"):
            u_td = r.find("td", class_="umaban")
            if u_td: cur = u_td.text.strip()
            txt = r.find("td", class_="danwa")
            if txt and cur: danwas[cur] = txt.text.strip()
            
    # èª¿æ•™
    driver.get(f"https://s.keibabook.co.jp/chihou/cyokyo/1/{race_id}")
    time.sleep(1)
    soup_c = BeautifulSoup(driver.page_source, "html.parser")
    cyokyos = {}
    tbl_c = soup_c.find_all("table", class_="cyokyo")
    for t in tbl_c:
        u_td = t.find("td", class_="umaban")
        tanpyo = t.find("td", class_="tanpyo")
        if u_td and tanpyo:
            cyokyos[u_td.text.strip()] = tanpyo.text.strip()

    return jockeys, danwas, cyokyos

def run_dify(text):
    if not DIFY_API_KEY: return "Dify API Keyæœªè¨­å®š"
    payload = {"inputs": {"text": text}, "response_mode": "blocking", "user": "bot"}
    headers = {"Authorization": f"Bearer {DIFY_API_KEY}", "Content-Type": "application/json"}
    try:
        res = requests.post("https://api.dify.ai/v1/workflows/run", headers=headers, json=payload, timeout=60)
        return res.json().get("data", {}).get("outputs", {}).get("text", "åˆ†æå®Œäº†ï¼ˆå‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆå–å¾—å¤±æ•—ï¼‰")
    except Exception as e: return f"Difyã‚¨ãƒ©ãƒ¼: {e}"

# ==================================================
# 3. UI & å®Ÿè¡Œ
# ==================================================
st.title("ğŸ‡ å—é–¢Ã—ãƒ–ãƒƒã‚¯ ç›¸æ€§åˆ†æBot")

jst = pytz.timezone('Asia/Tokyo')
today_jst = datetime.now(jst)

col1, col2 = st.columns(2)
with col1: target_date = st.date_input("åˆ†ææ—¥", today_jst)
with col2: place_code = st.selectbox("ç«¶é¦¬å ´", options=list(PLACE_NAMES.keys()), format_func=lambda x: f"{x}:{PLACE_NAMES[x]}", index=1)

all_races = st.checkbox("å…¨12ãƒ¬ãƒ¼ã‚¹ä¸€æ‹¬åˆ†æ", value=True)
selected = []
if not all_races:
    cols = st.columns(6)
    for i in range(1, 13):
        with cols[(i-1)//2]:
            if st.checkbox(f"{i}R", key=f"r{i}"): selected.append(i)
else: selected = list(range(1, 13))

if st.button("ğŸš€ åˆ†æã‚’é–‹å§‹ã™ã‚‹", type="primary", use_container_width=True):
    date_str = target_date.strftime("%Y%m%d")
    driver = get_driver()
    
    try:
        st.write("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")
        driver.get("https://s.keibabook.co.jp/login/login")
        driver.find_element(By.NAME, "login_id").send_keys(KEIBA_ID)
        driver.find_element(By.CSS_SELECTOR, "input[type='password']").send_keys(KEIBA_PASS)
        driver.find_element(By.CSS_SELECTOR, "input[type='submit']").click()
        
        st.write("ğŸ“¡ é–‹å‚¬æƒ…å ±ã‚’å–å¾—ä¸­...")
        nankan_base_id = get_nankan_base_id(driver, date_str, place_code)
        book_ids = fetch_book_race_ids(driver, date_str, place_code)
        
        if not book_ids:
            st.error(f"ç«¶é¦¬ãƒ–ãƒƒã‚¯ã§ {date_str} {PLACE_NAMES[place_code]} ã®ãƒ¬ãƒ¼ã‚¹IDãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        elif not nankan_base_id:
            st.error("å—é–¢å…¬å¼ã®ãƒ™ãƒ¼ã‚¹IDã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒˆæ§‹æˆãŒå¤‰æ›´ã•ã‚ŒãŸã‹ã€ãƒœãƒƒãƒˆæ¤œçŸ¥ã•ã‚ŒãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        else:
            st.success(f"å—é–¢ãƒ™ãƒ¼ã‚¹IDç‰¹å®š: {nankan_base_id}")
            for rid in book_ids:
                # ç«¶é¦¬ãƒ–ãƒƒã‚¯IDã‹ã‚‰ãƒ¬ãƒ¼ã‚¹ç•ªå·ã‚’æŠ½å‡º (é‡è¦: rid[10:12]ãŒRç•ªå·)
                r_num = int(rid[10:12])
                if r_num not in selected: continue
                
                with st.expander(f"ğŸ“Š {PLACE_NAMES[place_code]} {r_num}R (ID:{rid})", expanded=True):
                    status = st.empty()
                    status.info(f"{r_num}R ã®è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ä¸­...")
                    
                    # ãƒ‡ãƒ¼ã‚¿å–å¾—
                    jockeys, danwas, cyokyos = parse_book_data(driver, rid)
                    
                    merged = []
                    # å‡ºé¦¬è¡¨ã®é¦¬ç•ªé †ã«å‡¦ç†
                    for uma in sorted(jockeys.keys(), key=int):
                        info = jockeys[uma]
                        compat = fetch_jockey_trainer_stats(driver, nankan_base_id, r_num, uma)
                        dan = danwas.get(uma, "ï¼ˆãªã—ï¼‰")
                        cyo = cyokyos.get(uma, "ï¼ˆçŸ­è©•ãªã—ï¼‰")
                        alert = "ã€âš ï¸ä¹—ã‚Šæ›¿ã‚ã‚Šã€‘" if info["is_change"] else ""
                        merged.append(f"â–¼[é¦¬ç•ª{uma}] {info['name']} {alert}\n ç›¸æ€§: {compat}\n è«‡è©±: {dan}\n èª¿æ•™: {cyo}")
                    
                    prompt = f"{PLACE_NAMES[place_code]} {r_num}R åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿\n\n" + "\n".join(merged)
                    
                    status.info("ğŸ¤– AIåˆ†æã‚’å®Ÿè¡Œä¸­...")
                    ans = run_dify(prompt)
                    st.markdown(ans)
                    status.success("å®Œäº†")
                    
    finally:
        driver.quit()
